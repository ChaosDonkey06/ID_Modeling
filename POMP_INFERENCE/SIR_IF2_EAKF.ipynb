{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import os\n",
    "\n",
    "from global_config import config\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = config.get_property('results_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def eakf_step(x_prior, params_prior, obs_ens_time, obs_time, oev_time, dict_params_range, num_var=8):\n",
    "\n",
    "    prior_mean_ct = obs_ens_time.mean()\n",
    "    prior_var_ct  = obs_ens_time.var()\n",
    "\n",
    "    if prior_mean_ct == 0:\n",
    "        post_var_ct  = 1e-3\n",
    "        prior_var_ct = 1e-3\n",
    "\n",
    "    post_var_ct  = prior_var_ct * oev_time / (prior_var_ct + oev_time)\n",
    "    post_mean_ct = post_var_ct * (prior_mean_ct/prior_var_ct + obs_time / oev_time)\n",
    "    alpha        = oev_time / (oev_time+prior_var_ct); alpha = alpha**0.5\n",
    "    dy           = post_mean_ct + alpha*( obs_ens_time - prior_mean_ct ) - obs_ens_time\n",
    "\n",
    "    # adjust parameters\n",
    "    rr = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        A = np.cov(params_prior[idx_p,:], obs_ens_time)\n",
    "        rr.append( A[1,0] / prior_var_ct )\n",
    "\n",
    "    rr         = np.array(rr)\n",
    "    dx         = np.dot( np.expand_dims(rr,-1), np.expand_dims(dy, 0) )\n",
    "    param_post = params_prior + dx\n",
    "\n",
    "    # adjust variables\n",
    "    rr = []\n",
    "    for idx_var in range(num_var):\n",
    "        A = np.cov(x_prior[idx_var,:], obs_ens_time)\n",
    "        rr.append( A[1,0] / prior_var_ct )\n",
    "\n",
    "    rr       = np.array(rr)\n",
    "    dx       = np.dot( np.expand_dims(rr,-1), np.expand_dims(dy, 0) )\n",
    "    x_post   = x_prior + dx\n",
    "\n",
    "    obs_post    = obs_ens_time + dy\n",
    "\n",
    "    return x_post, param_post, obs_post\n",
    "\n",
    "def checkbound_params_old(dict_params_range, params_ens, num_ensembles=300):\n",
    "\n",
    "    params_update = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        loww = dict_params_range[p][0]\n",
    "        upp  = dict_params_range[p][1]\n",
    "\n",
    "        p_ens = params_ens[idx_p, :].copy()\n",
    "\n",
    "        idx_wrong = np.where(np.logical_or(p_ens <loww, p_ens > upp))[0]\n",
    "        idx_good  = np.where(np.logical_or(p_ens >=loww, p_ens <= upp))[0]\n",
    "\n",
    "\n",
    "        p_ens[idx_wrong] = np.median(p_ens[idx_good])\n",
    "        params_update.append(p_ens)\n",
    "\n",
    "        print(f\"{p}: {np.median(p_ens)}\")\n",
    "\n",
    "    return np.array(params_update)\n",
    "\n",
    "def checkbound_params(dict_params_range, params_ens, num_ensembles=300):\n",
    "    params_update = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        loww = dict_params_range[p][0]\n",
    "        upp  = dict_params_range[p][1]\n",
    "\n",
    "        p_ens = params_ens[idx_p, :].copy()\n",
    "\n",
    "        idx_wrong      = np.where(np.logical_or(p_ens <loww, p_ens > upp))[0]\n",
    "\n",
    "        idx_wrong_loww = np.where(p_ens < loww)[0]\n",
    "        idx_wrong_upp  = np.where(p_ens > upp)[0]\n",
    "\n",
    "        idx_good  = np.where(np.logical_or(p_ens >=loww, p_ens <= upp))[0]\n",
    "\n",
    "        p_ens[idx_wrong] = np.median(p_ens[idx_good])\n",
    "\n",
    "        np.put(p_ens, idx_wrong_loww, loww * (1+0.2*np.random.rand( idx_wrong_loww.shape[0])) )\n",
    "        np.put(p_ens, idx_wrong_upp, upp * (1-0.2*np.random.rand( idx_wrong_upp.shape[0])) )\n",
    "\n",
    "        params_update.append(p_ens)\n",
    "\n",
    "    return np.array(params_update)\n",
    "\n",
    "def checkbound_state_vars(x_state_ens, pop, num_params=8, num_ensembles=300):\n",
    "    loww = 0\n",
    "    upp  = pop\n",
    "    x_state_ens = np.clip(x_state_ens, 0, upp)\n",
    "    return x_state_ens\n",
    "\n",
    "def inflate_ensembles(ens, inflation_value=1.2, num_ensembles=300):\n",
    "    return np.mean(ens,1, keepdims=True)*np.ones((1,num_ensembles)) + inflation_value*(ens-np.mean(ens,1, keepdims=True)*np.ones((1,num_ensembles)))\n",
    "\n",
    "def b_transition(var, rate, dt=1):\n",
    "    kb        = np.maximum(1.0 - math.exp(-rate*dt), 0)\n",
    "    num_ind   = np.random.binomial(var, kb )\n",
    "\n",
    "    return num_ind\n",
    "\n",
    "def model(x, beta, gamma, report_rate=0.2, N=1e6):\n",
    "\n",
    "    S   = x[0]   # Susceptibles\n",
    "    I   = x[1]   # Infected Reported\n",
    "    R   = x[2]   # Recovered\n",
    "\n",
    "    foi =  beta * (I) / N\n",
    "\n",
    "    # Stochastic transitions\n",
    "    s2i     =  b_transition(S, foi)                 # susceptible to exposed\n",
    "    i2r     =  b_transition(I, gamma) # exposed to infected reported who are not going to die\n",
    "\n",
    "    # Updates\n",
    "    S    = S   - s2i       # Susceptible\n",
    "    I    = I   + s2i - i2r  # Infected reported\n",
    "    R    = R   + i2r       # Recovered\n",
    "    C    = np.random.binomial(s2i, report_rate)\n",
    "\n",
    "    return [S, I, R, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sample_params_uniform(dict_params_range, num_ensembles=100):\n",
    "    param_ens_prior = []\n",
    "    for p in dict_params_range.keys():\n",
    "        param_ens_prior.append( np.random.uniform( dict_params_range[p][0], dict_params_range[p][1]  , size=num_ensembles) )\n",
    "    return np.array( param_ens_prior )\n",
    "\n",
    "def get_truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm( (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd )\n",
    "\n",
    "def sample_params_normal(dict_params_range, params_mean, params_var, num_ensembles=300):\n",
    "    param_ens_prior = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        norm_gen = get_truncated_normal(mean=params_mean[idx_p], sd=params_var[idx_p]**(1/2), low=dict_params_range[p][0], upp=dict_params_range[p][1])\n",
    "\n",
    "        param_ens_prior.append( norm_gen.rvs(num_ensembles) )\n",
    "\n",
    "    return np.array( param_ens_prior )\n",
    "\n",
    "def create_df_response(samples, time, date_init ='2020-03-06',  quantiles = [50, 80, 95], forecast_horizon=27, dates=None, use_future=False):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        samples ([type]): [description]\n",
    "        time ([type]): [description]\n",
    "        date_init (str, optional): [description]. Defaults to '2020-03-06'.\n",
    "        forecast_horizon (int, optional): [description]. Defaults to 27.\n",
    "        use_future (bool, optional): [description]. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    if dates is not None:\n",
    "        dates_fitted = dates\n",
    "    else:\n",
    "        dates_fitted   = pd.date_range(start=pd.to_datetime(date_init), periods=time)\n",
    "        dates_forecast = pd.date_range(start=dates_fitted[-1]+datetime.timedelta(1), periods=forecast_horizon)\n",
    "\n",
    "    dates = list(dates_fitted)\n",
    "    types = ['estimate']*len(dates_fitted)\n",
    "    if use_future:\n",
    "        dates += list(dates_forecast)\n",
    "        types  += ['forecast']*len(dates_forecast)\n",
    "\n",
    "    results_df = pd.DataFrame(samples.T)\n",
    "    df_response = pd.DataFrame(index=dates)\n",
    "    # Calculate key statistics\n",
    "    df_response['mean']        = results_df.mean(axis=1).values\n",
    "    df_response['median']      = results_df.median(axis=1).values\n",
    "    df_response['std']         = results_df.std(axis=1).values\n",
    "\n",
    "    for quant in quantiles:\n",
    "        low_q  = ((100-quant)/2)/100\n",
    "        high_q = 1-low_q\n",
    "\n",
    "        df_response[f'low_{quant}']  = results_df.quantile(q=low_q, axis=1).values\n",
    "        df_response[f'high_{quant}'] = results_df.quantile(q=high_q, axis=1).values\n",
    "\n",
    "    df_response['type']        =  types\n",
    "    df_response.index.name = 'date'\n",
    "\n",
    "    return df_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def eakf_step(x_prior, params_prior, obs_ens_time, obs_time, oev_time, dict_params_range, num_var=4):\n",
    "\n",
    "    prior_mean_ct = obs_ens_time.mean()\n",
    "    prior_var_ct  = obs_ens_time.var()\n",
    "\n",
    "    if prior_mean_ct == 0:\n",
    "        post_var_ct  = 1e-3\n",
    "        prior_var_ct = 1e-3\n",
    "\n",
    "\n",
    "    post_var_ct  = prior_var_ct * oev_time / (prior_var_ct + oev_time)\n",
    "    post_mean_ct = post_var_ct * (prior_mean_ct/prior_var_ct + obs_time / oev_time)\n",
    "    alpha        = oev_time / (oev_time+prior_var_ct); alpha = alpha**0.5\n",
    "    dy           = post_mean_ct + alpha*( obs_ens_time - prior_mean_ct ) - obs_ens_time\n",
    "\n",
    "    # adjust parameters\n",
    "    rr = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        A = np.cov(params_prior[idx_p,:], obs_ens_time)\n",
    "        rr.append( A[1,0] / prior_var_ct )\n",
    "\n",
    "    rr         = np.array(rr)\n",
    "    dx         = np.dot( np.expand_dims(rr,-1), np.expand_dims(dy, 0) )\n",
    "    param_post = params_prior + dx\n",
    "\n",
    "    # adjust variables\n",
    "    rr = []\n",
    "    for idx_var in range(num_var):\n",
    "        A = np.cov(x_prior[idx_var,:], obs_ens_time)\n",
    "        rr.append( A[1,0] / prior_var_ct )\n",
    "\n",
    "    rr       = np.array(rr)\n",
    "    dx       = np.dot( np.expand_dims(rr,-1), np.expand_dims(dy, 0) )\n",
    "    x_post   = x_prior + dx\n",
    "\n",
    "    obs_post    = obs_ens_time + dy\n",
    "\n",
    "    return x_post, param_post, obs_post\n",
    "\n",
    "def checkbound_params_old(dict_params_range, params_ens, num_ensembles=300):\n",
    "\n",
    "    params_update = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        loww = dict_params_range[p][0]\n",
    "        upp  = dict_params_range[p][1]\n",
    "\n",
    "        p_ens = params_ens[idx_p, :].copy()\n",
    "\n",
    "        idx_wrong = np.where(np.logical_or(p_ens <loww, p_ens > upp))[0]\n",
    "        idx_good  = np.where(np.logical_or(p_ens >=loww, p_ens <= upp))[0]\n",
    "\n",
    "\n",
    "        p_ens[idx_wrong] = np.median(p_ens[idx_good])\n",
    "        params_update.append(p_ens)\n",
    "\n",
    "        print(f\"{p}: {np.median(p_ens)}\")\n",
    "\n",
    "    return np.array(params_update)\n",
    "\n",
    "def checkbound_params(dict_params_range, params_ens, num_ensembles=300):\n",
    "    params_update = []\n",
    "    for idx_p, p in enumerate(dict_params_range.keys()):\n",
    "        loww = dict_params_range[p][0]\n",
    "        upp  = dict_params_range[p][1]\n",
    "\n",
    "        p_ens = params_ens[idx_p, :].copy()\n",
    "\n",
    "        idx_wrong      = np.where(np.logical_or(p_ens <loww, p_ens > upp))[0]\n",
    "\n",
    "        idx_wrong_loww = np.where(p_ens < loww)[0]\n",
    "        idx_wrong_upp  = np.where(p_ens > upp)[0]\n",
    "\n",
    "        idx_good  = np.where(np.logical_or(p_ens >=loww, p_ens <= upp))[0]\n",
    "\n",
    "        p_ens[idx_wrong] = np.median(p_ens[idx_good])\n",
    "\n",
    "        np.put(p_ens, idx_wrong_loww, loww * (1+0.2*np.random.rand( idx_wrong_loww.shape[0])) )\n",
    "        np.put(p_ens, idx_wrong_upp, upp * (1-0.2*np.random.rand( idx_wrong_upp.shape[0])) )\n",
    "\n",
    "        params_update.append(p_ens)\n",
    "\n",
    "    return np.array(params_update)\n",
    "\n",
    "def checkbound_state_vars(x_state_ens, pop, num_params=8, num_ensembles=300):\n",
    "    loww = 0\n",
    "    upp  = pop\n",
    "    x_state_ens = np.clip(x_state_ens, 0, upp)\n",
    "    return x_state_ens\n",
    "\n",
    "def inflate_ensembles(ens, inflation_value=1.2, num_ensembles=300):\n",
    "    return np.mean(ens,1, keepdims=True)*np.ones((1,num_ensembles)) + inflation_value*(ens-np.mean(ens,1, keepdims=True)*np.ones((1,num_ensembles)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints and Misc:\n",
    "https://kingaa.github.io/sbied/mif/if2_settings.html\n",
    "\n",
    "\n",
    "- It is generally helpful to transform the parameters so that (on the estimation scale) they are real-valued, unconstrained, and have uncertainty on the order of 1 unit. \n",
    "    - Real positive value parameters estimated on log scale.\n",
    "    - Parameters in the range [0,1] estimated using a logistic transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of parameters.\n",
    "\n",
    "def logistic_transform(param_ensemble, destransform=False):\n",
    "    if ~ destransform:\n",
    "        # Return transformed parameters\n",
    "        return np.log(param_ensemble/(1-param_ensemble))\n",
    "\n",
    "    elif destransform:\n",
    "        # Return destransformed parameters\n",
    "        return 1/(1/np.exp(param_ensemble)+1)\n",
    "\n",
    "def log_transform(param_ensemble, destransform=False):\n",
    "    if ~ destransform:\n",
    "        # Return transformed parameters\n",
    "        return np.log(param_ensemble)\n",
    "    elif destransform:\n",
    "        return np.exp(param_ensemble)\n",
    "\n",
    "def random_walk_perturbation(param, param_std, num_params, num_ensembles):\n",
    "    return param + param_std * np.random.normal(size=(num_params, num_ensembles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_cooling(num_iteration_if, cooling_factor=0.9):\n",
    "    alphas = cooling_factor**np.arange(num_iteration_if)\n",
    "    return alphas**2\n",
    "\n",
    "def hyperbolic_cooling(num_iteration_if, cooling_factor=0.9):\n",
    "    alphas = 1/(1+cooling_factor*np.arange(num_iteration_if))\n",
    "    return alphas\n",
    "\n",
    "def cooling(num_iteration_if, type_cool=\"geometric\", cooling_factor=0.9):\n",
    "    if type_cool==\"geometric\":\n",
    "        return geometric_cooling(num_iteration_if, cooling_factor=cooling_factor)\n",
    "    elif type_cool==\"hyperbolic\":\n",
    "        return hyperbolic_cooling(num_iteration_if, cooling_factor=cooling_factor)\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def IF2_eakf(model, obs_df, param_prior_dict, if2_settings, perturb_time=False):\n",
    "\n",
    "    cooling_factor   = cooling(if2_settings[\"num_iters_mif\"], type_cool=if2_settings[\"type_cooling\"], cooling_factor=if2_settings[\"alpha_mif\"])\n",
    "\n",
    "    param_range      = np.array([v for k, v in param_prior_dict.items()])\n",
    "    std_param        = param_range[:,1]-param_range[:,0]\n",
    "    SIG              = std_param ** 2 / 4; #  initial covariance of parameters\n",
    "\n",
    "    perturbation     = np.array([std_param % list(np.round(std_param)+0.1)]).T\n",
    "\n",
    "    num_steps          = len(obs_df) -1\n",
    "\n",
    "\n",
    "    x_states_post_all  = np.full((if2_settings[\"num_state_vars\"],   if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan)   # Array to store state variables.\n",
    "    param_mean_iter    = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_iters_mif\"]+1), np.nan)                               # Array to store posterior parameters in iterations.\n",
    "    para_post_all      = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan)       # Array to store posterior parameters.\n",
    "    obs_post_all       = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps, if2_settings[\"num_iters_mif\"]), np.nan) # Array for store posterior observations\n",
    "    param_iter         = np.full((if2_settings[\"num_params\"],       if2_settings[\"num_ensembles\"], if2_settings[\"num_iters_mif\"]), np.nan)\n",
    "\n",
    "    dates_assimilation = obs_df.index.get_level_values(0).values\n",
    "    dates              = dates_assimilation\n",
    "    print(f\"Running MIF  \\n\")\n",
    "\n",
    "    for n in tqdm(range(if2_settings[\"num_iters_mif\"])):\n",
    "        if n==0:\n",
    "            p_prior               = sample_params_uniform(param_prior_dict, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            beta                  = p_prior[0,:]\n",
    "            gamma                 = p_prior[1,:]\n",
    "            x                     = np.array([[N-0.01*N, 0.01*N, 0, 0.01*N]]).T * np.ones((if2_settings[\"num_state_vars\"], if2_settings[\"num_ensembles\"]))\n",
    "            param_mean_iter[:, n] = np.mean(p_prior, -1)\n",
    "\n",
    "        else:\n",
    "            params_mean     = param_mean_iter[:,n]\n",
    "            params_var      = SIG * cooling_factor[n]\n",
    "            p_prior         = sample_params_normal(param_prior_dict, params_mean, params_var, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            beta            = p_prior[0,:]\n",
    "            gamma           = p_prior[1,:]\n",
    "            x               = np.array([[N-0.01*N, 0.01*N, 0, 0.01*N]]).T * np.ones((4, if2_settings[\"num_ensembles\"]))\n",
    "\n",
    "        param_post_time   = np.full((if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        x_post_time       = np.full((if2_settings[\"num_state_vars\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "        obs_post_time     = np.full((if2_settings[\"num_observations\"], if2_settings[\"num_ensembles\"], num_steps), np.nan)\n",
    "\n",
    "        idx_date_update   = 0\n",
    "\n",
    "\n",
    "        confirmed_t = np.zeros((if2_settings[\"num_ensembles\"], 1))\n",
    "        for idx_t, date in enumerate(dates[1:]):\n",
    "            # Integrate model\n",
    "            x_ens =[]\n",
    "            for idx_ens in range(if2_settings[\"num_ensembles\"]):\n",
    "                beta   = p_prior[0, idx_ens]\n",
    "                gamma  = p_prior[1, idx_ens]\n",
    "\n",
    "                x_ens.append(model(x[:,idx_ens], beta, gamma, report_rate, N))\n",
    "            x_ens = np.array(x_ens).T\n",
    "            x     = x_ens\n",
    "\n",
    "            # Inflate state variables\n",
    "            x = inflate_ensembles(x, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            x = checkbound_state_vars(x_state_ens=x, pop=N, num_params=if2_settings[\"num_params\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "            if perturb_time:\n",
    "                # Transform parameters for perturbation\n",
    "                #p_prior    = log_transform(p_prior, destransform=False)\n",
    "                std_params = perturbation*cooling_factor[n]\n",
    "                p_prior    = random_walk_perturbation(p_prior, std_params, if2_settings[\"num_params\"], if2_settings[\"num_ensembles\"])\n",
    "                #p_prior    = log_transform(p_prior, destransform=True)\n",
    "\n",
    "            # Inflate parameters\n",
    "            p_prior = inflate_ensembles(p_prior, inflation_value=if2_settings[\"lambda_inf\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "            p_prior = checkbound_params(param_prior_dict, p_prior, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "            confirmed_t  +=  np.expand_dims(x[-1,:], -1)\n",
    "\n",
    "            if pd.to_datetime(date) == pd.to_datetime(dates_assimilation[1:][idx_date_update]):\n",
    "                    oev_confirmed_time = oev_df.loc[date][\"oev\"]\n",
    "\n",
    "                    confirmed_time = obs_df.loc[date][\"confirmed\"]\n",
    "\n",
    "                    param_post = p_prior.copy()\n",
    "                    # Update parameters using confirmed deaths\n",
    "                    x_prior = x.copy()\n",
    "                    x_post, param_post, confirmed_obs_post = eakf_step(x, param_post, np.squeeze(confirmed_t), confirmed_time, oev_confirmed_time, param_prior_dict)\n",
    "\n",
    "                    x_post                                 = checkbound_state_vars(x_state_ens=x_post, pop=N, num_params=if2_settings[\"num_state_vars\"], num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "                    param_post                             = checkbound_params(param_prior_dict, params_ens=param_post, num_ensembles=if2_settings[\"num_ensembles\"])\n",
    "\n",
    "                    #if np.where(param_post==np.nan)\n",
    "                    x       = x_post.copy()\n",
    "                    # Use posterior and next prior\n",
    "                    p_prior = param_post.copy()\n",
    "\n",
    "                    obs_post_time[:,:,idx_date_update]    = confirmed_obs_post\n",
    "                    param_post_time[:,:,idx_date_update]  = param_post\n",
    "                    x_post_time[:,:,idx_date_update]      = x_post\n",
    "\n",
    "                    idx_date_update += 1\n",
    "\n",
    "                    confirmed_t = np.zeros((if2_settings[\"num_ensembles\"], 1))\n",
    "\n",
    "        x_states_post_all  = x_post_time\n",
    "        #np.put(x_states_post_all, [:,:,:,n], x_post_time )\n",
    "\n",
    "        obs_post_all[:,:,:,n]       = obs_post_time\n",
    "        para_post_all[:,:,:,n]      = param_post_time\n",
    "        param_iter[:,:,n]           = param_post_time.mean(-1)\n",
    "        param_mean_iter[:,n+1]      = param_post_time.mean(-1).mean(-1)\n",
    "\n",
    "    return x_states_post_all, obs_post_all, para_post_all, param_iter, param_mean_iter\n",
    "\n",
    "plt.rc('font', size=15) #controls default text size\n",
    "\n",
    "def plot_convergence_plots(theta, param_iter, path_to_save = None):\n",
    "    ittters  = param_iter.shape[-1]\n",
    "    beta_df  = create_df_response(param_iter[0,:,:], time=ittters)\n",
    "    gamma_df = create_df_response(param_iter[1,:,:], time=ittters)\n",
    "\n",
    "    beta_mle  = beta_df[\"mean\"].iloc[-1]\n",
    "    gamma_mle = gamma_df[\"mean\"].iloc[-1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12.5, 7.2), sharex=True)\n",
    "\n",
    "    ax[0].plot(range(ittters+1), theta[0,:], color=\"k\", lw=3, label=\"Mean\")\n",
    "    ax[0].fill_between(range(1,ittters+1), beta_df[\"low_95\"], beta_df[\"high_95\"], color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "    ax[0].fill_between(range(1,ittters+1), beta_df[\"low_50\"], beta_df[\"high_50\"], color=\"gray\", alpha=0.3, label=\"50% CI\")\n",
    "    ax[0].axhline(y=beta_truth, color=\"red\", linestyle=\"--\", lw=2, label=\"Truth\")\n",
    "\n",
    "    ax[1].plot(range(ittters+1), theta[1,:], color=\"k\", lw=3, label=\"Mean\")\n",
    "    ax[1].fill_between(range(1,ittters+1), gamma_df[\"low_95\"], gamma_df[\"high_95\"], color=\"gray\", alpha=0.3, label=\"95% CI\")\n",
    "    ax[1].fill_between(range(1,ittters+1), gamma_df[\"low_50\"], gamma_df[\"high_50\"], color=\"gray\", alpha=0.3, label=\"50% CI\")\n",
    "\n",
    "    ax[1].axhline(y=gamma_truth, color=\"red\", linestyle=\"--\", lw=2, label=\"Truth\")\n",
    "\n",
    "    ax[1].set_xlabel(\"IF2 Iteration\")\n",
    "    ax[0].set_ylabel(r\"$\\beta$\")\n",
    "    ax[1].set_ylabel(r\"$\\gamma$\")\n",
    "\n",
    "    ax[0].legend(loc=\"upper right\")\n",
    "    ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "    fig.suptitle(r\"$\\beta=${:0.4f}, $\\beta_{{MAP}}=${:0.4f} | $\\gamma=${:0.4f}, $\\gamma_{{MAP}}=${:0.4f}\".format(beta_truth, beta_mle, gamma_truth, gamma_mle))\n",
    "    plt.tight_layout()\n",
    "    if path_to_save:\n",
    "        fig.savefig(path_to_save, dpi=300, transparent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MIF  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:01<00:34,  1.37it/s]"
     ]
    }
   ],
   "source": [
    "r_ceros = [2.5, 5, 12]\n",
    "for R0 in r_ceros:\n",
    "    gamma = 1/7\n",
    "    beta  = R0*gamma\n",
    "\n",
    "\n",
    "    N     = 1e6\n",
    "\n",
    "    beta_truth  = beta\n",
    "    gamma_truth = gamma\n",
    "    report_rate = 0.3\n",
    "\n",
    "    num_days = 100\n",
    "    x  = [N-0.01*N, 0.01*N, 0, 0]\n",
    "\n",
    "    x_sol      = np.zeros((num_days, 4))\n",
    "\n",
    "    x_sol[0, :] = x\n",
    "    for d_idx in range(1, num_days):\n",
    "        x_sol[d_idx, :] = model(x_sol[d_idx-1, :], beta, gamma, report_rate,  N)\n",
    "\n",
    "    x_sol_df = pd.DataFrame(x_sol, columns=[\"S\", \"I\", \"R\", \"C\"]); x_sol_df.index.name=\"date\"\n",
    "\n",
    "    obs_df         = x_sol_df[[\"C\"]].rename(columns={\"C\": \"confirmed\"})\n",
    "    oev_df         = pd.DataFrame(columns=[\"date\", \"oev\"])\n",
    "    oev_df[\"date\"] = obs_df.index.values\n",
    "    oev_df         = oev_df.set_index(\"date\")\n",
    "    oev_df[\"oev\"]  = np.maximum(20,  1+(0.2*obs_df[\"confirmed\"].values)**2  )\n",
    "\n",
    "\n",
    "    param_prior_dict          = {}\n",
    "    param_prior_dict[\"beta\"]  = [0.2, 2.15]   # Contact rate         [1/days]\n",
    "    param_prior_dict[\"gamma\"] = [1/15, 1/3]  # Recovery rate range  [1/days]\n",
    "\n",
    "    params_type_dict  = {\"beta\": \"log_transform\", \"gamma\": \"log_transform\"} # Define type of transformation for estimate\n",
    "    transform_dict    = {\"beta\": True, \"gamma\": True}                       # Define if tranform or nor parameters\n",
    "\n",
    "    if2_settings = {}\n",
    "    if2_settings[\"num_params\"]       = len(param_prior_dict)\n",
    "    if2_settings[\"num_state_vars\"]   = 4\n",
    "    if2_settings[\"num_observations\"] = 1\n",
    "    if2_settings[\"lambda_inf\"]       = 1.01\n",
    "    if2_settings[\"num_iters_mif\"]    = 50\n",
    "    if2_settings[\"alpha_mif\"]        = 0.9 # Variance shrinking factor\n",
    "    if2_settings[\"type_cooling\"]     = \"geometric\"\n",
    "    if2_settings[\"num_ensembles\"]    = 300\n",
    "\n",
    "    x_states_post_all, obs_post_all, para_post_all, param_iter, param_mean_iter = IF2_eakf(model, obs_df, param_prior_dict, if2_settings,  perturb_time=True)\n",
    "    plot_convergence_plots(param_mean_iter, param_iter, path_to_save = os.path.join(results_dir, \"eakf_if2_beta_{:.2f}_gamma_{:.2f}_reprate_{}.png\".format(beta_truth, gamma_truth, report_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
